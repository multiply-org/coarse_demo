{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T17:40:25.090628Z",
     "start_time": "2018-02-05T17:40:25.085418Z"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": "true"
   },
   "outputs": [],
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T17:59:17.453675Z",
     "start_time": "2018-02-05T17:59:17.113975Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feeding the models\n",
    "\n",
    "* DGVMs require a parametrisation of the land surface\n",
    "* ... at a coarse scale (10s-100s km)\n",
    "* ... over large periods of time (decades!)\n",
    "* But do we prescribe these parameters?\n",
    "* Can we assess DGVM assumptions?\n",
    "* Does EO help?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How can EO help?\n",
    "\n",
    "* Modelling of **energy fluxes**\n",
    "    * Radiation budget\n",
    "    * Photosynthesis\n",
    "* We can interpret EO data in terms of \n",
    "    * Same parameters\n",
    "    * Same physical models\n",
    "* We can either \n",
    "    * Compare models with \"reality\"\n",
    "    * Prescribe parameters for the model\n",
    "* But remember that EO data was **limited**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Albedo (Bi-hemispherical reflectance)\n",
    "\n",
    "* Albedo: fraction of incoming radiation that is **reflected**\n",
    "* Consider **broad spectral bands**\n",
    "* In MULTIPLY, aim to **infer** albedo from combining different sensors\n",
    "    * Coarse spatial resolution\n",
    "        * MODIS\n",
    "        * S3/OLCI\n",
    "        * S3/SLSTR\n",
    "        * VIIRS\n",
    "* Two measurements per time step per pixel: **VIS**ible and **N**ear**I**nfra**R**ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](bhr_MMR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpreting albedo\n",
    "\n",
    "* Use a simple model\n",
    "    * ... which one can use inside a DGVM (Seller's, JRC-TIP, etc)\n",
    "* Describe albedo as a function of\n",
    "    * optical properties of soil\n",
    "    * optical properties of leaves\n",
    "    * Amount and structure of canopy\n",
    "* Only that we simplify the structure $\\longrightarrow$ **effective LAI**\n",
    "* So, we have two (noisy!)observations...\n",
    "    * ... and 7 parameters!\n",
    "* How do we go about that?!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The model\n",
    "\n",
    "* **JRC-TIP**\n",
    "* 7 parameters $\\longrightarrow$ predicts $\\alpha_{VIS}$ & $\\alpha_{NIR}$\n",
    "* Simplify 3D structure to have simple physics\n",
    "* We don't actually use the model\n",
    "    * $\\longrightarrow$ We use **emulators**\n",
    "* The model is present in some DGVMs already\n",
    "* ... or we could use another BHR model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Priors\n",
    "\n",
    "* Need to limit the solution space!\n",
    "* What are our parameters?\n",
    "    * leaf reflectance and transmittance (VIS+NIR)\n",
    "    * soil albedo (VIS+NIR)\n",
    "    * effective LAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Leaves\n",
    "![](tip_priors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Setting up the problem\n",
    "\n",
    "* First, we need some observations\n",
    "    * Currently, using MODIS MCD43 Albedo product\n",
    "    * Will use MULTIPLY coarse resolution product when available\n",
    "* We also need  a **state mask**\n",
    "* And finally, our RT model is stored as an **emulator** in a file\n",
    "    * If you want to change the RT model, you change the emulator file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T17:59:23.931564Z",
     "start_time": "2018-02-05T17:59:23.652726Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "mcd43a1_dir does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d876a3592a14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m bhr_data =  BHRObservations(emulator, tile, mcd43a1_dir, start_time,\n\u001b[0;32m---> 16\u001b[0;31m                                 end_time=None, mcd43a2_dir=None)\n\u001b[0m",
      "\u001b[0;32m/home/ucfajlg/.local/lib/python2.7/site-packages/KaFKA-0.0.0-py2.7.egg/kafka/input_output/observations.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, emulator, tile, mcd43a1_dir, start_time, ulx, uly, dx, dy, end_time, mcd43a2_dir)\u001b[0m\n\u001b[1;32m    228\u001b[0m         RetrieveBRDFDescriptors.__init__(self, tile,\n\u001b[1;32m    229\u001b[0m                                          \u001b[0mmcd43a1_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                                          mcd43a2_dir)\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Python3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m#  super().__init__(tile, mcd43a1_dir, start_time, end_time,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ucfajlg/.local/lib/python2.7/site-packages/BRDF_descriptors/BRDF_descriptors.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tile, mcd43a1_dir, start_time, end_time, mcd43a2_dir)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcd43a1_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcd43a1_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mcd43a1_dir does not exist!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         self.a1_granules = find_granules(self.mcd43a1_dir, tile, \"A1\",\n\u001b[1;32m    191\u001b[0m                                          self.start_time, self.end_time)\n",
      "\u001b[0;31mIOError\u001b[0m: mcd43a1_dir does not exist!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from kafka.input_output import BHRObservations, KafkaOutput\n",
    "\n",
    "parameter_list = [\"w_vis\", \"x_vis\", \"a_vis\",\n",
    "                     \"w_nir\", \"x_nir\", \"a_nir\", \"TeLAI\"]\n",
    "    \n",
    "tile = \"h17v05\"\n",
    "start_time = \"2017001\"    \n",
    "emulator = \"./SAIL_emulator_both_500trainingsamples.pkl\"\n",
    "mcd43a1_dir=\"/data/selene/ucfajlg/Ujia/MCD43/\"\n",
    "    \n",
    "mask = np.zeros((2400,2400),dtype=np.bool8)\n",
    "mask[650:730, 1180:1280] = True # Arros\n",
    "\n",
    "bhr_data =  BHRObservations(emulator, tile, mcd43a1_dir, start_time,\n",
    "                                end_time=None, mcd43a2_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T17:59:25.534358Z",
     "start_time": "2018-02-05T17:59:25.484011Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from kafka.inference import block_diag\n",
    "\n",
    "class JRCPrior(object):\n",
    "    \"\"\"Dummpy 2.7/3.6 prior class following the same interface as 3.6 only\n",
    "    version.\"\"\"\n",
    "\n",
    "    def __init__ (self, parameter_list, state_mask):\n",
    "        \"\"\"It makes sense to have the list of parameters and state mask\n",
    "        defined at this point, as they won't change during processing.\"\"\"\n",
    "        self.mean, self.covar, self.inv_covar = self._tip_prior() \n",
    "        self.parameter_list = parameter_list\n",
    "        if isinstance(state_mask, (np.ndarray, np.generic) ):\n",
    "            self.state_mask = state_mask\n",
    "        else:\n",
    "            self.state_mask = self._read_mask(state_mask)\n",
    "            \n",
    "    def _read_mask(self, fname):\n",
    "        \"\"\"Tries to read the mask as a GDAL dataset\"\"\"\n",
    "        if not os.path.exists(fname):\n",
    "            raise IOError(\"State mask is neither an array or a file that exists!\")\n",
    "        g = gdal.Open(fname)\n",
    "        if g is None:\n",
    "            raise IOError(\"{:s} can't be opened with GDAL!\".format(fname))\n",
    "        mask = g.ReadAsArray()\n",
    "        return mask\n",
    "\n",
    "    def _tip_prior(self):\n",
    "        \"\"\"The JRC-TIP prior in a convenient function which is fun for the whole\n",
    "        family. Note that the effective LAI is here defined in transformed space\n",
    "        where TLAI = exp(-0.5*LAIe).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The mean prior vector, covariance and inverse covariance matrices.\"\"\"\n",
    "        # broadly TLAI 0->7 for 1sigma\n",
    "        sigma = np.array([0.12, 0.7, 0.0959, 0.15, 1.5, 0.2, 0.5])\n",
    "        x0 = np.array([0.17, 1.0, 0.1, 0.7, 2.0, 0.18, np.exp(-0.5*2.)])\n",
    "        # The individual covariance matrix\n",
    "        little_p = np.diag(sigma**2).astype(np.float32)\n",
    "        little_p[5, 2] = 0.8862*0.0959*0.2\n",
    "        little_p[2, 5] = 0.8862*0.0959*0.2\n",
    "\n",
    "        inv_p = np.linalg.inv(little_p)\n",
    "        return x0, little_p, inv_p\n",
    "\n",
    "    def process_prior ( self, time, inv_cov=True):\n",
    "        # Presumably, self._inference_prior has some method to retrieve \n",
    "        # a bunch of files for a given date...\n",
    "        n_pixels = self.state_mask.sum()\n",
    "        x0 = np.array([self.mean for i in xrange(n_pixels)]).flatten()\n",
    "        if inv_cov:\n",
    "            inv_covar_list = [self.inv_covar for m in xrange(n_pixels)]\n",
    "            inv_covar = block_diag(inv_covar_list, dtype=np.float32)\n",
    "            return x0, inv_covar\n",
    "        else:\n",
    "            covar_list = [self.covar for m in xrange(n_pixels)]\n",
    "            covar = block_diag(covar_list, dtype=np.float32)\n",
    "            return x0, covar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The prior...\n",
    "\n",
    "* We use a prior object, `JRCPrior`. \n",
    "* This prior encodes the JRC TIP prior \n",
    "* Prior is subjective: if you don't agree with it, you can set **your own**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T17:59:27.880588Z",
     "start_time": "2018-02-05T17:59:27.876716Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "the_prior = JRCPrior(parameter_list, mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So we have a prior, observations, a model (associated to the observations)...\n",
    "\n",
    "What else do we need? \n",
    "    * We need a starting point\n",
    "\n",
    "Currently MULTIPLY inference engine works as a **filter**\n",
    "    * It inverts observations **sequentially**\n",
    "    * We need to give it starting prior\n",
    "    * ... Which we can query the prior engine for\n",
    "    * The prior is defined as a\n",
    "        * Mean vector $\\vec{\\mu}$, `x_forecast`\n",
    "        * Prior **inverse** covariance matrix $\\mathbf{C}_{prior}^{-1}$, `P_forecast_inv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T17:42:23.530070Z",
     "start_time": "2018-02-05T17:42:22.983734Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inference pixels: 8000\n",
      "Size of the state vector: 56000\n",
      "Size of the inverse covariance matrix: 56000 * 56000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f92a23b2350>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEyCAYAAACYrUmUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n98kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92a2490b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query the JRC-TIP prior for a mean and inverse covariance matrix\n",
    "x_forecast, P_forecast_inv = the_prior.process_prior(None)\n",
    "print(\"Number of inference pixels: {:d}\".format(mask.sum()))\n",
    "print(\"Size of the state vector: {:d}\".format(x_forecast.shape[0]))\n",
    "print(\"Size of the inverse covariance matrix: {:d} * {:d}\".format(\n",
    "    P_forecast_inv.shape[0], P_forecast_inv.shape[1]))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.spy(P_forecast_inv, c=\"0.8\", ms=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have set everything set up, except for **when** we want the system to report an **inference**\n",
    "\n",
    "* Observations are every 16 days\n",
    "* Assume we want to invert every observation\n",
    "* If we wanted (eg) daily estimates, the system could **interpolate** using a **dynamic temporal model**\n",
    "* ... but not using it this time\n",
    "\n",
    "So let's define the inference grid: a set of times when we will produced inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T17:59:49.786349Z",
     "start_time": "2018-02-05T17:59:49.780404Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2017, 7, 1, 0, 0), datetime.datetime(2017, 7, 17, 0, 0), datetime.datetime(2017, 8, 2, 0, 0), datetime.datetime(2017, 8, 18, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "base = datetime.datetime(2017,7,1)\n",
    "num_days = 60\n",
    "time_grid = list((base + datetime.timedelta(days=x) \n",
    "                  for x in range(0, num_days, 16)))\n",
    "print(time_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nearly there!\n",
    "\n",
    "This would be quite useless if we didn't set up somewhere to save the data. \n",
    "\n",
    "In this case, we use GeoTIFF files for different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "projection, geotransform = bhr_data.define_output()\n",
    "output = KafkaOutput(parameter_list, geotransform, projection, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T18:03:47.256326Z",
     "start_time": "2018-02-05T18:03:47.232070Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bhr_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c5b8f9c21c19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_nonlinear_observation_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m kf = LinearKalman(bhr_data, output, mask, \n\u001b[0m\u001b[1;32m      6\u001b[0m                       \u001b[0mcreate_nonlinear_observation_operator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0mstate_propagation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bhr_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Putting it all together\n",
    "from kafka import LinearKalman\n",
    "from kafka.inference import create_nonlinear_observation_operator\n",
    "\n",
    "kf = LinearKalman(bhr_data, output, mask, \n",
    "                      create_nonlinear_observation_operator, parameter_list,\n",
    "                      state_propagation=None,\n",
    "                      prior=the_prior,\n",
    "                      linear=False)\n",
    "\n",
    "\n",
    "kf.run(time_grid, x_forecast, None, P_forecast_inv, iter_obs_op=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
